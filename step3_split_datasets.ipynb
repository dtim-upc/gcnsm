{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read labels CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def read_dataset(path,drop_columns=None,keep_columns=None):\n",
    "    #get rid of useless columns\n",
    "    csv_data = pd.read_csv(path)\n",
    "    \n",
    "    if keep_columns != None:\n",
    "        #keep only these columns\n",
    "        return csv_data.filter(items=keep_columns)\n",
    "    \n",
    "    if drop_columns!= None:\n",
    "        #drop these and keep the rest\n",
    "        return csv_data.drop(drop_columns, axis=1)\n",
    "    \n",
    "    #finally, didn't drop or filter any column\n",
    "    return csv_data\n",
    "\n",
    "df_ds = read_dataset(\"./openML/openml_203ds_datasets_matching.csv\",keep_columns=[\"'dataset1_id'\", \"'dataset2_id'\",\"'matching_topic'\"]);\n",
    "df_not_matching = df_ds[df_ds[\"'matching_topic'\"] == 0 ].to_numpy()\n",
    "df_matching = df_ds[df_ds[\"'matching_topic'\"] == 1 ].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19758\n",
      "543\n"
     ]
    }
   ],
   "source": [
    "print(len(df_not_matching))\n",
    "print(len(df_matching))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549\n",
      "543\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "def get_splits(data,splits=14):\n",
    "    kf = KFold(n_splits=splits,shuffle=True)\n",
    "    neg_samples = []\n",
    "    i = []\n",
    "    #for train_index, test_index in kf.split(data.index.values.tolist()):\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        _train = data[train_index]\n",
    "        _test = data[test_index]\n",
    "        break\n",
    "    return _train,_test\n",
    "\n",
    "def concat_shuffle(a1,a2):\n",
    "    out = np.concatenate((a1,a2)) \n",
    "    np.random.shuffle(out)\n",
    "    return out\n",
    "\n",
    "discard,neg_set = get_splits(df_not_matching,36)\n",
    "neg_train,neg_test = get_splits(neg_set,6)\n",
    "pos_train,pos_test = get_splits(df_matching,6)\n",
    "\n",
    "print(len(neg_set))\n",
    "print(len(df_matching))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "909\n",
      "183\n",
      "19209\n"
     ]
    }
   ],
   "source": [
    "train = concat_shuffle(pos_train,neg_train)\n",
    "test = concat_shuffle(pos_test,neg_test)\n",
    "print(len(train))\n",
    "print(len(test))\n",
    "print(len(discard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#control there are not overlapping pairs\n",
    "def overlapping_pairs(data):\n",
    "    control = []\n",
    "    for r in data:\n",
    "        comb1 = str(\"{}_{}\".format(r[0],r[1]))\n",
    "        comb2 = str(\"{}_{}\".format(r[1],r[0]))\n",
    "        if comb1 in control or comb2 in control:\n",
    "            return True\n",
    "        else:\n",
    "            control.append(comb1)\n",
    "            control.append(comb2)\n",
    "    return False\n",
    "\n",
    "print(overlapping_pairs(train))\n",
    "print(overlapping_pairs(test))\n",
    "print(overlapping_pairs(discard))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.DataFrame(data=train,columns=[\"ds1\",\"ds2\",\"matching\"]) \n",
    "df_test = pd.DataFrame(data=test,columns=[\"ds1\",\"ds2\",\"matching\"]) \n",
    "df_test_only_negative = pd.DataFrame(data=discard,columns=[\"ds1\",\"ds2\",\"matching\"]) \n",
    "df_train.to_csv(\"train2.csv\",index=False)\n",
    "df_test.to_csv(\"test2.csv\",index=False)\n",
    "df_test_only_negative.to_csv(\"test_only_negative2.csv\",index=False)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
