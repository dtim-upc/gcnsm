{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read labels CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def read_dataset(path,drop_columns=None,keep_columns=None):\n",
    "    #get rid of useless columns\n",
    "    csv_data = pd.read_csv(path)\n",
    "    \n",
    "    if keep_columns != None:\n",
    "        #keep only these columns\n",
    "        return csv_data.filter(items=keep_columns)\n",
    "    \n",
    "    if drop_columns!= None:\n",
    "        #drop these and keep the rest\n",
    "        return csv_data.drop(drop_columns, axis=1)\n",
    "    \n",
    "    #finally, didn't drop or filter any column\n",
    "    return csv_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def get_splits(data,splits=14):\n",
    "    kf = KFold(n_splits=splits,shuffle=True)\n",
    "    neg_samples = []\n",
    "    i = []\n",
    "    #create one split and return - for now, just 1 fold for experiments\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        _train = data[train_index]\n",
    "        _test = data[test_index]\n",
    "        break\n",
    "    return _train,_test\n",
    "\n",
    "def concat_shuffle(a1,a2):\n",
    "    out = np.concatenate((a1,a2)) \n",
    "    np.random.shuffle(out)\n",
    "    return out\n",
    "\n",
    "#control there are not overlapping pairs\n",
    "def overlapping_pairs(data):\n",
    "    control = []\n",
    "    for r in data:\n",
    "        comb1 = str(\"{}_{}\".format(r[0],r[1]))\n",
    "        comb2 = str(\"{}_{}\".format(r[1],r[0]))\n",
    "        if comb1 in control or comb2 in control:\n",
    "            return True\n",
    "        else:\n",
    "            control.append(comb1)\n",
    "            control.append(comb2)\n",
    "    return False\n",
    "\n",
    "def split_ds(file_name):\n",
    "    df_ds = read_dataset(\"./datasets/\"+file_name,keep_columns=[\"'dataset1_id'\", \"'dataset2_id'\",\"'matching_topic'\"]);\n",
    "    df_not_matching = df_ds[df_ds[\"'matching_topic'\"] == 0 ].to_numpy()\n",
    "    df_matching = df_ds[df_ds[\"'matching_topic'\"] == 1 ].to_numpy()\n",
    "\n",
    "    np.random.shuffle(df_not_matching)\n",
    "    np.random.shuffle(df_matching)\n",
    "\n",
    "    #Sample 2x negative per positive pair\n",
    "    neg_sample = df_not_matching[0:len(df_matching)*2]\n",
    "\n",
    "    #1 split for test, 5 for training\n",
    "    neg_train,neg_test = get_splits(neg_sample,6)\n",
    "    pos_train,pos_test = get_splits(df_matching,6)\n",
    "\n",
    "    #concat negative and possitive pairs splits\n",
    "    train = concat_shuffle(pos_train,neg_train)\n",
    "    test = concat_shuffle(pos_test,neg_test)\n",
    "\n",
    "    train_matching = np.array([x for x in train if x[2]==1])\n",
    "    train_not_matching = np.array([x for x in train if x[2]==0])\n",
    "    test_matching = np.array([x for x in test if x[2]==1])\n",
    "    test_not_matching = np.array([x for x in test if x[2]==0])\n",
    "\n",
    "    #data augmentation for positive data\n",
    "    train_matching.T[[0, 1]] = train_matching.T[[1, 0]]\n",
    "    train=np.concatenate((train,train_matching))\n",
    "    np.random.shuffle(train)\n",
    "    train_matching = np.array([x for x in train if x[2]==1])\n",
    "    train_not_matching = np.array([x for x in train if x[2]==0])\n",
    "\n",
    "#     print(\"Training set\")\n",
    "#     print(len(train))\n",
    "#     print(\"Training pos\")\n",
    "#     print(len(train_matching))\n",
    "#     print(\"Training neg\")\n",
    "#     print(len(train_not_matching))\n",
    "\n",
    "#     print(\"Test set\")\n",
    "#     print(len(test))\n",
    "#     print(\"Test pos\")\n",
    "#     print(len(test_matching))\n",
    "#     print(\"Test neg\")\n",
    "#     print(len(test_not_matching))\n",
    "\n",
    "\n",
    "#     #train pairs will have repeated possitive pairs\n",
    "#     print(overlapping_pairs(train))\n",
    "#     print(overlapping_pairs(test))\n",
    "\n",
    "    #write files\n",
    "    df_train = pd.DataFrame(data=train,columns=[\"ds1\",\"ds2\",\"matching\"]) \n",
    "    df_test = pd.DataFrame(data=test,columns=[\"ds1\",\"ds2\",\"matching\"]) \n",
    "    df_train.to_csv(\"./datasets/\"+file_name+\"_train.csv\",index=False)\n",
    "    df_test.to_csv(\"./datasets/\"+file_name+\"_test.csv\",index=False)\n",
    "    \n",
    "    print(\"Train/Test split done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
