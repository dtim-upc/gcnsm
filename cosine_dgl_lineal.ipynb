{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read graph of metafeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "g_x = nx.read_gpickle(\"encoded_fasttext.gpickle\")\n",
    "#g = nx.read_gpickle(\"encoded_features.gpickle\")\n",
    "#g = nx.read_gpickle(\"siimple.gpickle\")\n",
    "order = 0\n",
    "for x,n in sorted(g_x.nodes(data=True)):\n",
    "    t = n['tipo']\n",
    "    if t == \"dataset\":\n",
    "        n['tipo'] = 0\n",
    "    if t == \"feature dataset\":\n",
    "        n['tipo'] = 1\n",
    "    if t == \"literal dataset\":\n",
    "        n['tipo'] = 2\n",
    "    if t == \"attribute\":\n",
    "        n['tipo'] = 3\n",
    "    if t == \"feature attribute\":\n",
    "        n['tipo'] = 4\n",
    "    if t == \"literal attribute\":\n",
    "        n['tipo'] = 5  \n",
    "    n['order']=order\n",
    "    order+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [x for x,y in g_x.nodes(data=True) if y['tipo']==0]\n",
    "order = [y['order'] for x,y in g_x.nodes(data=True) if y['tipo']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_order = dict(zip(datasets,order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_order['DS_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get 60% train, 20% val and 20% test from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def read_dataset(path,drop_columns=None,keep_columns=None):\n",
    "    #get rid of useless columns\n",
    "    csv_data = pd.read_csv(path)\n",
    "    \n",
    "    if keep_columns != None:\n",
    "        #keep only these columns\n",
    "        return csv_data.filter(items=keep_columns)\n",
    "    \n",
    "    if drop_columns!= None:\n",
    "        #drop these and keep the rest\n",
    "        return csv_data.drop(drop_columns, axis=1)\n",
    "    \n",
    "    #finally, didn't drop or filter any column\n",
    "    return csv_data     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "def get_samples(df):\n",
    "    train_mask = []\n",
    "    val_mask = []\n",
    "    test_mask = []\n",
    "    for index, row in df.iterrows():\n",
    "        if row[2] == 1:\n",
    "            if randrange(0, 10) <= 7:\n",
    "                train_mask.append([row[0],row[1],row[2]])\n",
    "            else:\n",
    "                test_mask.append([map_order['DS_'+str(row[0])],map_order['DS_'+str(row[1])],row[2]])\n",
    "#                 if index % 2 == 0:\n",
    "#                     val_mask.append([map_order['DS_'+str(row[0])],map_order['DS_'+str(row[1])],row[2]])\n",
    "#                 else:\n",
    "#                     test_mask.append([map_order['DS_'+str(row[0])],map_order['DS_'+str(row[1])],row[2]])\n",
    "        else:\n",
    "            if randrange(0, 10) > 8:\n",
    "#                 if randrange(0, 30) <= 21:\n",
    "                if randrange(0, 30) <= 24:\n",
    "                    train_mask.append([map_order['DS_'+str(row[0])],map_order['DS_'+str(row[1])],row[2]])\n",
    "                else:\n",
    "                    test_mask.append([map_order['DS_'+str(row[0])],map_order['DS_'+str(row[1])],row[2]])\n",
    "#                     if index % 2 == 0:\n",
    "#                         val_mask.append([map_order['DS_'+str(row[0])],map_order['DS_'+str(row[1])],row[2]])\n",
    "#                     else:\n",
    "#                         test_mask.append([map_order['DS_'+str(row[0])],map_order['DS_'+str(row[1])],row[2]])\n",
    "    return train_mask,test_mask\n",
    "#     return train_mask,val_mask,test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 2126 Test samples: 473\n"
     ]
    }
   ],
   "source": [
    "df_matching = read_dataset(\"./openml_203ds_datasets_matching.csv\",keep_columns=[\"'dataset1_id'\", \"'dataset2_id'\",\"'matching_topic'\"]);\n",
    "# train_mask,val_mask,test_mask = get_samples(df_matching)\n",
    "# print(\"Train samples: \"+str(len(train_mask)) + \" Val samples: \"+str(len(val_mask))+ \" Test samples: \"+str(len(test_mask)))\n",
    "train_mask,test_mask = get_samples(df_matching)\n",
    "print(\"Train samples: \"+str(len(train_mask)) + \" Test samples: \"+str(len(test_mask)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[374, 523, 0],\n",
       " [374, 433, 0],\n",
       " [374, 482, 0],\n",
       " [374, 545, 0],\n",
       " [571, 499, 0],\n",
       " [571, 554, 0],\n",
       " [571, 541, 0],\n",
       " [571, 547, 0],\n",
       " [571, 574, 0],\n",
       " [576, 418, 0],\n",
       " [576, 547, 1],\n",
       " [576, 422, 1],\n",
       " [576, 443, 0],\n",
       " [576, 512, 1],\n",
       " [576, 465, 0],\n",
       " [576, 484, 1],\n",
       " [417, 464, 1],\n",
       " [417, 486, 1],\n",
       " [417, 447, 0],\n",
       " [417, 426, 0],\n",
       " [417, 449, 0],\n",
       " [417, 490, 0],\n",
       " [418, 443, 0],\n",
       " [418, 441, 1],\n",
       " [418, 555, 0],\n",
       " [464, 486, 1],\n",
       " [464, 543, 0],\n",
       " [464, 382, 1],\n",
       " [464, 387, 0],\n",
       " [464, 431, 0],\n",
       " [464, 573, 0],\n",
       " [466, 510, 1],\n",
       " [466, 420, 0],\n",
       " [466, 442, 0],\n",
       " [470, 486, 1],\n",
       " [470, 493, 0],\n",
       " [470, 517, 0],\n",
       " [470, 551, 0],\n",
       " [470, 387, 0],\n",
       " [470, 527, 0],\n",
       " [470, 552, 0],\n",
       " [476, 480, 0],\n",
       " [476, 485, 0],\n",
       " [476, 400, 0],\n",
       " [486, 508, 1],\n",
       " [486, 515, 0],\n",
       " [486, 389, 0],\n",
       " [486, 446, 0],\n",
       " [486, 544, 0],\n",
       " [491, 493, 0],\n",
       " [491, 551, 1],\n",
       " [491, 389, 0],\n",
       " [495, 574, 1],\n",
       " [495, 410, 1],\n",
       " [495, 490, 0],\n",
       " [496, 493, 0],\n",
       " [499, 543, 0],\n",
       " [499, 550, 0],\n",
       " [499, 427, 0],\n",
       " [499, 542, 0],\n",
       " [501, 549, 0],\n",
       " [508, 416, 0],\n",
       " [515, 521, 0],\n",
       " [515, 561, 0],\n",
       " [515, 389, 0],\n",
       " [515, 425, 0],\n",
       " [515, 530, 0],\n",
       " [520, 570, 1],\n",
       " [520, 536, 0],\n",
       " [520, 522, 0],\n",
       " [520, 490, 0],\n",
       " [520, 573, 0],\n",
       " [521, 429, 0],\n",
       " [523, 480, 0],\n",
       " [523, 381, 0],\n",
       " [523, 388, 0],\n",
       " [523, 411, 0],\n",
       " [523, 415, 0],\n",
       " [523, 437, 0],\n",
       " [524, 518, 0],\n",
       " [554, 567, 0],\n",
       " [554, 408, 0],\n",
       " [554, 448, 1],\n",
       " [554, 455, 1],\n",
       " [554, 478, 0],\n",
       " [570, 433, 0],\n",
       " [570, 412, 0],\n",
       " [439, 525, 0],\n",
       " [439, 403, 0],\n",
       " [447, 477, 0],\n",
       " [447, 493, 0],\n",
       " [447, 445, 1],\n",
       " [447, 459, 0],\n",
       " [447, 519, 0],\n",
       " [469, 415, 1],\n",
       " [469, 448, 0],\n",
       " [469, 489, 0],\n",
       " [471, 517, 0],\n",
       " [471, 383, 1],\n",
       " [471, 392, 0],\n",
       " [471, 413, 0],\n",
       " [472, 480, 0],\n",
       " [472, 386, 0],\n",
       " [472, 425, 0],\n",
       " [473, 450, 0],\n",
       " [473, 451, 0],\n",
       " [474, 502, 0],\n",
       " [474, 506, 0],\n",
       " [474, 517, 0],\n",
       " [474, 539, 0],\n",
       " [474, 404, 0],\n",
       " [474, 463, 0],\n",
       " [477, 498, 0],\n",
       " [477, 558, 0],\n",
       " [477, 575, 0],\n",
       " [477, 402, 0],\n",
       " [477, 433, 0],\n",
       " [480, 493, 0],\n",
       " [480, 553, 0],\n",
       " [480, 400, 0],\n",
       " [480, 402, 0],\n",
       " [480, 423, 0],\n",
       " [480, 526, 0],\n",
       " [480, 533, 0],\n",
       " [480, 376, 0],\n",
       " [481, 459, 1],\n",
       " [481, 377, 0],\n",
       " [485, 563, 0],\n",
       " [485, 564, 1],\n",
       " [487, 408, 0],\n",
       " [488, 395, 0],\n",
       " [488, 434, 0],\n",
       " [488, 565, 0],\n",
       " [492, 558, 1],\n",
       " [492, 451, 0],\n",
       " [492, 542, 0],\n",
       " [493, 566, 0],\n",
       " [493, 574, 0],\n",
       " [493, 382, 0],\n",
       " [493, 410, 0],\n",
       " [493, 423, 0],\n",
       " [493, 449, 0],\n",
       " [497, 536, 0],\n",
       " [497, 552, 0],\n",
       " [498, 459, 0],\n",
       " [498, 542, 0],\n",
       " [498, 549, 0],\n",
       " [498, 573, 0],\n",
       " [502, 516, 1],\n",
       " [502, 540, 0],\n",
       " [502, 448, 0],\n",
       " [504, 411, 0],\n",
       " [504, 413, 0],\n",
       " [506, 432, 0],\n",
       " [506, 443, 0],\n",
       " [506, 455, 0],\n",
       " [506, 457, 0],\n",
       " [507, 545, 0],\n",
       " [509, 407, 0],\n",
       " [509, 511, 0],\n",
       " [509, 403, 0],\n",
       " [510, 431, 0],\n",
       " [510, 412, 0],\n",
       " [513, 383, 1],\n",
       " [516, 567, 0],\n",
       " [516, 396, 0],\n",
       " [516, 434, 1],\n",
       " [516, 442, 0],\n",
       " [517, 538, 0],\n",
       " [517, 518, 1],\n",
       " [525, 535, 0],\n",
       " [525, 420, 0],\n",
       " [525, 449, 0],\n",
       " [534, 537, 0],\n",
       " [534, 404, 0],\n",
       " [534, 432, 0],\n",
       " [535, 380, 1],\n",
       " [535, 391, 0],\n",
       " [535, 420, 0],\n",
       " [535, 456, 0],\n",
       " [535, 544, 0],\n",
       " [535, 412, 0],\n",
       " [536, 539, 0],\n",
       " [536, 395, 0],\n",
       " [536, 462, 0],\n",
       " [536, 542, 0],\n",
       " [536, 528, 0],\n",
       " [537, 378, 0],\n",
       " [538, 541, 1],\n",
       " [538, 435, 1],\n",
       " [538, 403, 0],\n",
       " [539, 558, 0],\n",
       " [539, 391, 0],\n",
       " [539, 421, 0],\n",
       " [540, 391, 0],\n",
       " [540, 454, 0],\n",
       " [540, 379, 0],\n",
       " [543, 562, 0],\n",
       " [543, 400, 0],\n",
       " [546, 428, 0],\n",
       " [547, 422, 1],\n",
       " [547, 426, 0],\n",
       " [548, 551, 1],\n",
       " [548, 569, 0],\n",
       " [548, 574, 0],\n",
       " [548, 400, 0],\n",
       " [548, 407, 0],\n",
       " [548, 415, 1],\n",
       " [548, 441, 0],\n",
       " [550, 419, 0],\n",
       " [550, 437, 0],\n",
       " [551, 440, 0],\n",
       " [553, 533, 0],\n",
       " [556, 424, 0],\n",
       " [558, 409, 0],\n",
       " [558, 430, 0],\n",
       " [558, 559, 1],\n",
       " [562, 399, 0],\n",
       " [562, 422, 0],\n",
       " [563, 566, 1],\n",
       " [563, 569, 1],\n",
       " [563, 398, 0],\n",
       " [564, 440, 0],\n",
       " [567, 393, 0],\n",
       " [567, 404, 1],\n",
       " [567, 448, 0],\n",
       " [568, 381, 0],\n",
       " [568, 400, 0],\n",
       " [569, 407, 0],\n",
       " [574, 410, 1],\n",
       " [574, 456, 0],\n",
       " [380, 394, 0],\n",
       " [381, 433, 0],\n",
       " [381, 427, 0],\n",
       " [382, 463, 0],\n",
       " [383, 460, 0],\n",
       " [384, 390, 0],\n",
       " [385, 390, 0],\n",
       " [386, 388, 1],\n",
       " [386, 394, 1],\n",
       " [386, 401, 1],\n",
       " [386, 445, 0],\n",
       " [386, 527, 0],\n",
       " [387, 398, 1],\n",
       " [387, 421, 0],\n",
       " [388, 395, 1],\n",
       " [388, 398, 1],\n",
       " [388, 441, 0],\n",
       " [389, 414, 0],\n",
       " [390, 391, 1],\n",
       " [390, 400, 1],\n",
       " [390, 414, 0],\n",
       " [390, 450, 0],\n",
       " [390, 452, 0],\n",
       " [391, 394, 1],\n",
       " [391, 395, 1],\n",
       " [391, 398, 1],\n",
       " [391, 401, 1],\n",
       " [391, 443, 0],\n",
       " [392, 395, 1],\n",
       " [392, 396, 1],\n",
       " [392, 398, 1],\n",
       " [392, 399, 1],\n",
       " [392, 402, 1],\n",
       " [392, 410, 0],\n",
       " [393, 398, 1],\n",
       " [393, 401, 1],\n",
       " [394, 398, 1],\n",
       " [394, 399, 1],\n",
       " [394, 400, 1],\n",
       " [396, 441, 0],\n",
       " [397, 400, 1],\n",
       " [397, 401, 1],\n",
       " [397, 402, 1],\n",
       " [397, 522, 0],\n",
       " [398, 399, 1],\n",
       " [398, 409, 0],\n",
       " [398, 527, 0],\n",
       " [399, 414, 0],\n",
       " [401, 402, 1],\n",
       " [406, 408, 0],\n",
       " [406, 423, 0],\n",
       " [406, 442, 0],\n",
       " [406, 462, 0],\n",
       " [407, 462, 1],\n",
       " [407, 527, 0],\n",
       " [408, 422, 0],\n",
       " [408, 431, 0],\n",
       " [410, 422, 1],\n",
       " [410, 424, 0],\n",
       " [410, 434, 0],\n",
       " [413, 414, 1],\n",
       " [413, 459, 0],\n",
       " [414, 454, 0],\n",
       " [415, 429, 0],\n",
       " [416, 425, 0],\n",
       " [416, 453, 0],\n",
       " [419, 442, 0],\n",
       " [420, 446, 0],\n",
       " [420, 452, 0],\n",
       " [424, 443, 0],\n",
       " [424, 533, 0],\n",
       " [426, 433, 0],\n",
       " [426, 434, 0],\n",
       " [426, 455, 0],\n",
       " [430, 528, 0],\n",
       " [433, 442, 0],\n",
       " [433, 526, 0],\n",
       " [434, 443, 1],\n",
       " [434, 527, 0],\n",
       " [437, 452, 1],\n",
       " [443, 445, 0],\n",
       " [443, 462, 0],\n",
       " [444, 461, 0],\n",
       " [446, 533, 1],\n",
       " [450, 452, 1],\n",
       " [450, 458, 1],\n",
       " [451, 530, 0],\n",
       " [453, 457, 1],\n",
       " [454, 457, 1],\n",
       " [455, 456, 1],\n",
       " [458, 529, 0],\n",
       " [459, 529, 0],\n",
       " [500, 416, 0],\n",
       " [500, 426, 0],\n",
       " [375, 523, 1],\n",
       " [375, 554, 1],\n",
       " [375, 507, 0],\n",
       " [479, 486, 1],\n",
       " [479, 508, 1],\n",
       " [479, 521, 0],\n",
       " [479, 554, 0],\n",
       " [479, 540, 0],\n",
       " [479, 546, 0],\n",
       " [479, 382, 1],\n",
       " [479, 446, 0],\n",
       " [479, 532, 0],\n",
       " [494, 394, 0],\n",
       " [494, 445, 0],\n",
       " [494, 533, 0],\n",
       " [512, 547, 1],\n",
       " [512, 568, 0],\n",
       " [557, 504, 0],\n",
       " [557, 510, 0],\n",
       " [557, 558, 0],\n",
       " [557, 435, 0],\n",
       " [557, 552, 0],\n",
       " [465, 428, 0],\n",
       " [465, 514, 0],\n",
       " [467, 469, 0],\n",
       " [467, 402, 0],\n",
       " [467, 406, 0],\n",
       " [467, 448, 1],\n",
       " [467, 455, 1],\n",
       " [503, 543, 1],\n",
       " [503, 387, 0],\n",
       " [503, 433, 1],\n",
       " [511, 551, 1],\n",
       " [511, 415, 1],\n",
       " [511, 444, 0],\n",
       " [514, 383, 0],\n",
       " [514, 419, 0],\n",
       " [514, 420, 0],\n",
       " [518, 391, 0],\n",
       " [518, 519, 1],\n",
       " [519, 561, 0],\n",
       " [519, 440, 0],\n",
       " [376, 396, 0],\n",
       " [376, 429, 0],\n",
       " [376, 532, 0],\n",
       " [378, 382, 0],\n",
       " [379, 456, 0],\n",
       " [379, 461, 0],\n",
       " [379, 412, 0],\n",
       " [421, 423, 0],\n",
       " [421, 433, 0],\n",
       " [436, 443, 0],\n",
       " [475, 454, 1],\n",
       " [475, 436, 0],\n",
       " [478, 517, 0],\n",
       " [478, 558, 1],\n",
       " [478, 565, 1],\n",
       " [482, 507, 1],\n",
       " [482, 566, 0],\n",
       " [482, 380, 0],\n",
       " [482, 395, 0],\n",
       " [482, 398, 0],\n",
       " [482, 432, 0],\n",
       " [482, 555, 1],\n",
       " [483, 392, 0],\n",
       " [484, 547, 1],\n",
       " [484, 568, 0],\n",
       " [484, 376, 0],\n",
       " [484, 542, 0],\n",
       " [489, 426, 0],\n",
       " [489, 451, 1],\n",
       " [489, 458, 1],\n",
       " [490, 553, 0],\n",
       " [490, 518, 0],\n",
       " [505, 509, 0],\n",
       " [505, 556, 0],\n",
       " [505, 567, 0],\n",
       " [505, 440, 0],\n",
       " [505, 451, 1],\n",
       " [505, 454, 1],\n",
       " [542, 445, 0],\n",
       " [542, 460, 0],\n",
       " [545, 555, 0],\n",
       " [549, 435, 0],\n",
       " [552, 381, 0],\n",
       " [552, 451, 0],\n",
       " [552, 531, 0],\n",
       " [552, 573, 1],\n",
       " [555, 569, 0],\n",
       " [555, 533, 0],\n",
       " [565, 455, 0],\n",
       " [573, 410, 0],\n",
       " [573, 433, 0],\n",
       " [573, 452, 0],\n",
       " [573, 377, 0],\n",
       " [573, 532, 0],\n",
       " [412, 532, 0],\n",
       " [529, 532, 0]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep graph library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "#convert from networkx to graph deep library format\n",
    "g = dgl.DGLGraph()\n",
    "#gdl.from_networkx(g,['vector'])\n",
    "g.from_networkx(g_x,node_attrs=['tipo','vector'], edge_attrs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import dgl.function as fn\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph\n",
    "\n",
    "gcn_msg = fn.copy_src(src='vector', out='m')\n",
    "gcn_reduce = fn.mean(msg='m', out='vector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "\n",
    "    def forward(self, g,feature):\n",
    "        # Creating a local scope so that all the stored ndata and edata\n",
    "        # (such as the `'h'` ndata below) are automatically popped out\n",
    "        # when the scope exits.\n",
    "        with g.local_scope():\n",
    "            g.ndata['vector'] = feature\n",
    "            g.update_all(gcn_msg, gcn_reduce)\n",
    "            h = g.ndata['vector']\n",
    "            return self.linear(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Constrastive(nn.Module):\n",
    "#     def __init__(self, in_feats, out_feats):\n",
    "#         super(Constrastive, self).__init__()\n",
    "#         self.linear = nn.Linear(in_feats, out_feats)\n",
    "\n",
    "#     def forward(self, g,feature):\n",
    "#         # Creating a local scope so that all the stored ndata and edata\n",
    "#         # (such as the `'h'` ndata below) are automatically popped out\n",
    "#         # when the scope exits.\n",
    "#         with g.local_scope():\n",
    "#             g.ndata['vector'] = feature\n",
    "#             g.update_all(gcn_msg, gcn_reduce)\n",
    "#             h = g.ndata['vector']\n",
    "#             return self.linear(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layer1): GCNLayer(\n",
      "    (linear): Linear(in_features=300, out_features=300, bias=True)\n",
      "  )\n",
      "  (layer2): GCNLayer(\n",
      "    (linear): Linear(in_features=300, out_features=300, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = GCNLayer(300, 300)\n",
    "        self.layer2 = GCNLayer(300, 300)\n",
    "    \n",
    "    def forward(self, g,features):\n",
    "        #x = F.relu(self.layer1(g, features))\n",
    "        x = F.leaky_relu(self.layer1(g, features))\n",
    "        #x = F.relu(self.layer2(g, x))\n",
    "        x = self.layer2(g, x)\n",
    "        return x\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "# def cosine_vectors(vec1,vec2):\n",
    "#     cos = th.nn.CosineSimilarity()\n",
    "#     c1 = cos(vec1,vec2)\n",
    "#     c2 = (1- cosine(vec1,vec2))\n",
    "#     print(c1-c2)\n",
    "#     return c1\n",
    "\n",
    "# def resultSet_train(features,mask):\n",
    "#     indices = []\n",
    "#     labels = []\n",
    "#     for n in mask:\n",
    "#         resultCos = cosine(features[n[0]],features[n[1]])\n",
    "#         # index 0 is not similar, index 1 is similar\n",
    "#         result = [1 - resultCos , resultCos]\n",
    "#         indices.append(result)\n",
    "#         labels.append(n[2])\n",
    "#     return th.tensor(indices, requires_grad=True),th.tensor(labels)\n",
    "\n",
    "\n",
    "def resultSet_train(features,mask):\n",
    "    v1 = []\n",
    "    v2 = []\n",
    "    labels = []\n",
    "    for n in mask:\n",
    "        v1.append(features[n[0]])\n",
    "        v2.append(features[n[1]])\n",
    "        if n[2] == 0:\n",
    "            n[2] = -1\n",
    "        labels.append(n[2])\n",
    "    return th.stack(v1),th.stack(v2),th.tensor(labels)\n",
    "\n",
    "\n",
    "def resultSet_eval(features,mask):\n",
    "    indices = []\n",
    "    labels = []\n",
    "    for n in mask:\n",
    "        resultCos = (1 - cosine(features[n[0]],features[n[1]]))\n",
    "        # index 0 is not similar, index 1 is similar\n",
    "        result = th.tensor([1 - resultCos , resultCos])\n",
    "        # get the index that is greater\n",
    "        out = th.argmax(result)\n",
    "        indices.append(out)\n",
    "        labels.append(n[2])\n",
    "    return th.tensor(indices),th.tensor(labels)\n",
    "\n",
    "def evaluate(model, g, features, mask):\n",
    "    model.eval()\n",
    "    with th.no_grad():\n",
    "        embeddings = model(g, features)\n",
    "        indices , labels = resultSet_eval(embeddings,mask)\n",
    "        correct = th.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = Net()\n",
    "# net.train()\n",
    "# embeddings = net(g, g.ndata['vector'])\n",
    "# indices,labels = resultSet_train(embeddings,train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e1,e2,labels = resultSet_train(embeddings,train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_tensor = th.cat(e1,dim=0)\n",
    "#my_tensor = th.stack(e1)\n",
    "#my_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "# net = Net()\n",
    "# optimizer = th.optim.Adam(net.parameters(), lr=1e-3)\n",
    "# dur = []\n",
    "# loss_func = nn.CosineEmbeddingLoss()\n",
    "for epoch in range(10):\n",
    "    t0 = time.time()\n",
    "    \n",
    "    net.train()\n",
    "    embeddings = net(g, g.ndata['vector'])\n",
    "    v1,v2,labels = resultSet_train(embeddings,train_mask)\n",
    "    loss = loss_func(v1,v2, labels)\n",
    "    optimizer.zero_grad()\n",
    "    #loss.backward(retain_graph=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    dur.append(time.time() - t0)\n",
    "    \n",
    "    #acc = evaluate(net, g, embeddings.detach(), test_mask)\n",
    "    acc = evaluate(net, g, g.ndata['vector'], test_mask)\n",
    "    print(\"Epoch {:05d} | Loss {:.4f} | Test Acc {:.4f} | Time(s) {:.4f}\".format(\n",
    "            epoch+10, loss.item(), acc, np.mean(dur)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#th.tensor(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import numpy as np\n",
    "# net = Net()\n",
    "# #g, features, labels, train_mask, test_mask\n",
    "\n",
    "# optimizer = th.optim.Adam(net.parameters(), lr=1e-2)\n",
    "# dur = []\n",
    "# for epoch in range(20):\n",
    "#     if epoch >=3:\n",
    "#         t0 = time.time()\n",
    "\n",
    "#     net.train()\n",
    "#     embeddings = net(g, g.ndata['vector'])\n",
    "#     indices,labels = resultSet_train(embeddings.detach(),train_mask)\n",
    "#     logp = F.logsigmoid(indices)\n",
    "#     loss = F.nll_loss(logp, labels)\n",
    "    \n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "    \n",
    "#     if epoch >=3:\n",
    "#         dur.append(time.time() - t0)\n",
    "    \n",
    "#     acc = evaluate(net, g, embeddings.detach(), test_mask)\n",
    "#     print(\"Epoch {:05d} | Loss {:.4f} | Test Acc {:.4f} | Time(s) {:.4f}\".format(\n",
    "#             epoch, loss.item(), acc, np.mean(dur)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data from a specific node\n",
    "g.nodes[0].data\n",
    "#get data from nodes\n",
    "g.ndata\n",
    "#another way of accessing data from a node\n",
    "g.ndata['tipo'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.has_edge_between(374,17619)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.ndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in g.nodes:\n",
    "    print (n.data['tipo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
